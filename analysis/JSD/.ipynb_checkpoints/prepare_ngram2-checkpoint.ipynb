{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e6fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/ImageCorpus.arpa\n",
      "-6.701576744068246\n",
      "0.0\n",
      "-6.402492584788194\n",
      "-3.5087249861476777\n",
      "-3.5087249861476777\n",
      "-3.5676796840931693\n",
      "-3.63032887982037\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.53776795244263\n",
      "-3.5087249861476777\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5087249861476777\n",
      "-4.766207230929363\n",
      "-3.5985138313319616\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "-3.5985138313319616\n",
      "-3.768794604129057\n",
      "-3.5985138313319616\n",
      "-3.53776795244263\n",
      "-3.5087249861476777\n",
      "-3.6631895321995067\n",
      "-3.53776795244263\n",
      "-3.5676796840931693\n",
      "-3.53776795244263\n",
      "-3.5676796840931693\n",
      "-3.5985138313319616\n",
      "-3.5087249861476777\n",
      "-3.5676796840931693\n",
      "-3.53776795244263\n",
      "-3.5985138313319616\n",
      "-3.5676796840931693\n",
      "-3.5676796840931693\n",
      "processing ./data/LibriTranscription.arpa\n",
      "-7.109994321060426\n",
      "0.0\n",
      "-6.808733067574948\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7028250806977594\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.8006494873395744\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.8006494873395744\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.9090915743622032\n",
      "-3.7028250806977594\n",
      "-3.775281907370059\n",
      "-3.998912655737789\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.9090915743622032\n",
      "-6.808733067574948\n",
      "processing ./data/LibriTrain.arpa\n",
      "-7.034686433525981\n",
      "0.0\n",
      "-6.736973924185825\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-4.03533149286113\n",
      "-3.713195693698095\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.8187178725642985\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.738550839708109\n",
      "-3.8187178725642985\n",
      "-4.2249919730934105\n",
      "processing ./data/wiki103.arpa\n",
      "-6.8545379323128595\n",
      "0.0\n",
      "-6.556044616367669\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.608216003879802\n",
      "-3.5815034839574684\n",
      "-3.635662127412763\n",
      "-3.608216003879802\n",
      "-3.663882610312498\n",
      "-3.635662127412763\n",
      "-3.635662127412763\n",
      "-3.608216003879802\n",
      "-3.608216003879802\n",
      "-3.608216003879802\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.663882610312498\n",
      "-3.608216003879802\n",
      "-3.608216003879802\n",
      "-3.635662127412763\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.7854745305427064\n",
      "-3.5815034839574684\n",
      "-4.08467013494126\n",
      "-3.663882610312498\n",
      "-3.608216003879802\n",
      "-3.663882610312498\n",
      "-3.635662127412763\n",
      "-3.608216003879802\n",
      "-3.608216003879802\n",
      "-3.663882610312498\n",
      "-3.5815034839574684\n",
      "-3.5815034839574684\n",
      "-3.663882610312498\n",
      "-3.663882610312498\n",
      "-3.9617535375070516\n",
      "-3.7854745305427064\n",
      "processing ./data/LibriLM.arpa\n",
      "-7.034686433525981\n",
      "0.0\n",
      "-6.736973924185825\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-4.03533149286113\n",
      "-3.713195693698095\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.713195693698095\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.8187178725642985\n",
      "-3.6884675416089046\n",
      "-3.6884675416089046\n",
      "-3.738550839708109\n",
      "-3.8187178725642985\n",
      "-4.2249919730934105\n",
      "processing ./data/NewsCrawl.arpa\n",
      "-7.109994321060426\n",
      "0.0\n",
      "-6.808733067574948\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7028250806977594\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.8006494873395744\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7028250806977594\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.8006494873395744\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.9090915743622032\n",
      "-3.7028250806977594\n",
      "-3.775281907370059\n",
      "-3.998912655737789\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.7263987166213237\n",
      "-3.9090915743622032\n",
      "-6.808733067574948\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "\n",
    "NGRAM_T = '\\\\%d-grams'\n",
    "UNK = \"<unk>\"\n",
    "START = \"<s>\"\n",
    "END = \"</s>\"\n",
    "\n",
    "class LM:\n",
    "    def __init__(self,arpafile=None,start=START,end=END,unk=UNK,fromFile=None):\n",
    "        \"\"\"\n",
    "        Load arpafile to get words and assign ids\n",
    "        Unigram table indexed by word id into tuple of prob and backoff\n",
    "        Bigram table indexed by (word1id, word2id) -> prob\n",
    "        \"\"\"\n",
    "        if fromFile is not None:\n",
    "            self.from_file(fromFile)\n",
    "            return \n",
    "\n",
    "        fid = open(arpafile,'r')\n",
    "        self.read_header(fid)\n",
    "        self.wordToInt = dict()\n",
    "        self.unigrams = dict()\n",
    "        self.bigrams = dict()\n",
    "        self.scale = math.log(10) #scale everything from log10 to ln\n",
    "        if self.isTrigram:\n",
    "            self.trigrams = dict()\n",
    "            self.bigrams = dict()\n",
    "\n",
    "        self.dict_to_default_dict()\n",
    "\n",
    "        self.load_ug(fid) # read unigram lm and word map, TODO provide list of allowed chars and scrub those not contained\n",
    "        self.load_bg(fid) # read bigram lm\n",
    "        if self.isTrigram: # if trigram lm, read that too\n",
    "            self.load_tg(fid)\n",
    "        self.start = self.wordToInt[start]\n",
    "        self.end = self.wordToInt[end]\n",
    "        self.unk = self.wordToInt[unk]\n",
    "        fid.close()\n",
    "\n",
    "    def dict_to_default_dict(self):\n",
    "        self.wordToInt = collections.defaultdict(lambda : -1,self.wordToInt)\n",
    "        self.unigrams = collections.defaultdict(lambda : (0.0,0.0),self.unigrams)\n",
    "        if self.isTrigram:\n",
    "            self.trigrams = collections.defaultdict(int,self.trigrams)\n",
    "            self.bigrams = collections.defaultdict(lambda : (0.0,0.0),self.bigrams)\n",
    "        else:\n",
    "            self.bigrams = collections.defaultdict(int,self.bigrams)\n",
    "\n",
    "    def default_dict_to_dict(self):\n",
    "        self.wordToInt = dict(self.wordToInt)\n",
    "        self.unigrams = dict(self.unigrams)\n",
    "        if self.isTrigram:\n",
    "            self.trigrams = dict(self.trigrams)\n",
    "            self.bigrams = dict(self.bigrams)\n",
    "        else:\n",
    "            self.bigrams = dict(self.bigrams)\n",
    "\n",
    "\n",
    "    def read_header(self,fid):\n",
    "        while fid.readline().strip() != \"\\\\data\\\\\":\n",
    "            continue\n",
    "        line = fid.readline()\n",
    "        assert'ngram 1' in line, \"Something wrong with file format.\"\n",
    "        self.numWords = int(line.strip().split('=')[1])\n",
    "        line = fid.readline()\n",
    "        assert 'ngram 2' in line, \"Must at least provide bigram LM\"\n",
    "        line = fid.readline()\n",
    "        if 'ngram 3' in line:\n",
    "            self.isTrigram = True\n",
    "        else:\n",
    "            self.isTrigram = False\n",
    "\n",
    "    def load_ug(self,fid):\n",
    "        count = 0\n",
    "        while NGRAM_T%1 not in fid.readline():\n",
    "            continue\n",
    "        while True:\n",
    "            line = fid.readline().strip().split()\n",
    "            if len(line)==0:\n",
    "                break\n",
    "            self.wordToInt[line[1]] = count\n",
    "            if len(line)==3:\n",
    "                self.unigrams[count] = (self.scale*float(line[0]),\n",
    "                                        self.scale*float(line[2]))\n",
    "            else:\n",
    "                self.unigrams[count] = (self.scale*float(line[0]),0.0)\n",
    "            count += 1\n",
    " \n",
    "    def load_bg(self,fid):\n",
    "        while NGRAM_T%2 not in fid.readline():\n",
    "            continue\n",
    "        while True:\n",
    "            line = fid.readline().strip().split()\n",
    "            if len(line)==0 or \"\\\\end\\\\\" == line[0]:\n",
    "                break\n",
    "            key = (self.wordToInt[line[1]],self.wordToInt[line[2]])\n",
    "            if self.isTrigram: \n",
    "                if len(line)==4:\n",
    "                    self.bigrams[key] = (self.scale*float(line[0]),\n",
    "                                         self.scale*float(line[3]))\n",
    "                else:\n",
    "                    self.bigrams[key] = (self.scale*float(line[0]),\n",
    "                                         0.0)\n",
    "            else:\n",
    "                self.bigrams[key] = self.scale*float(line[0])\n",
    "\n",
    "    def load_tg(self,fid):\n",
    "        while NGRAM_T%3 not in fid.readline():\n",
    "            continue\n",
    "        while True:\n",
    "            line = fid.readline().strip().split()\n",
    "            if len(line)==0 or \"\\\\end\\\\\" == line[0]:\n",
    "                break\n",
    "            key = (self.wordToInt[line[1]],self.wordToInt[line[2]],\n",
    "                   self.wordToInt[line[3]])\n",
    "            self.trigrams[key] = self.scale*float(line[0])\n",
    "\n",
    "    def get_word_id(self,word):\n",
    "        \"\"\"\n",
    "        Returns word id for words in vocab and UNK id otherwise.\n",
    "        \"\"\"\n",
    "        id = self.wordToInt[word]\n",
    "        if id==-1:\n",
    "            return self.unk\n",
    "        else:\n",
    "            return id\n",
    "\n",
    "    def ug_prob(self,wid):\n",
    "        \"\"\"\n",
    "        Returns unigram probility of word.\n",
    "        \"\"\"\n",
    "        return self.unigrams[wid][0]\n",
    "\n",
    "    def bg_prob(self,w1,w2):\n",
    "        \"\"\"\n",
    "        Returns bigram probability p(w2 | w1),\n",
    "        uses backoff if bigram does not exist.\n",
    "        \"\"\"\n",
    "        key = (w1,w2)\n",
    "        val = self.bigrams[key]\n",
    "        if val == 0:\n",
    "            val += self.unigrams[w1][1] + self.unigrams[w2][0]\n",
    "        return val\n",
    "\n",
    "    def tg_prob(self,w1,w2,w3):\n",
    "        \"\"\"\n",
    "        Returns trigram probability of p(w3 | w1, w2) :\n",
    "        p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)\n",
    "                        else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)\n",
    "                        else                         p(wd3|w2)\n",
    "        p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)\n",
    "                    else              bo_wt_1(wd1)*p_1(wd2)\n",
    "        \"\"\"\n",
    "        val = self.trigrams[(w1,w2,w3)]\n",
    "        # backoff to bigram\n",
    "        if val == 0:\n",
    "            val += self.bigrams[(w2,w3)][0]\n",
    "            # backoff to unigram\n",
    "            if val == 0:\n",
    "                val += self.unigrams[w3][0]\n",
    "                val += self.unigrams[w2][1]\n",
    "            val += self.bigrams[(w1,w2)][1]\n",
    "        return val\n",
    "\n",
    "    def score_bg(self,sentence):\n",
    "        words = [self.get_word_id(w) for w in sentence.strip().split()]\n",
    "        val = 0.0\n",
    "        val += self.bg_prob(self.start,words[0])\n",
    "        for i in range(len(words)-1):\n",
    "            val += self.bg_prob(words[i],words[i+1])\n",
    "        #val += self.bg_prob(words[-1],self.end)\n",
    "        return val\n",
    "\n",
    "    def score_tg(self,sentence):\n",
    "        assert self.isTrigram,\\\n",
    "                \"Can't score sentence as trigram with bigram lm.\"\n",
    "        words = [self.get_word_id(w) for w in sentence.strip().split()]\n",
    "        val = 0.0\n",
    "        if len(words) == 1:\n",
    "            w1 = self.start\n",
    "            w3 = self.end\n",
    "        else:\n",
    "            w1 = words[-2]\n",
    "            w3 = words[1]\n",
    "        val += self.tg_prob(self.start,self.start,words[0])\n",
    "        val += self.tg_prob(self.start,words[0],w3)\n",
    "        for i in range(len(words)-2):\n",
    "            val += self.tg_prob(words[i],words[i+1],words[i+2])\n",
    "        #if w3 != self.end:\n",
    "        #    val += self.tg_prob(w1,words[-1],self.end)\n",
    "        return val\n",
    "\n",
    "    def to_file(self,file):\n",
    "        import cPickle as pickle\n",
    "        self.default_dict_to_dict()\n",
    "        with open(file,'w') as fid:\n",
    "            pickle.dump([self.isTrigram, self.start, self.end, self.unk, self.scale],fid)\n",
    "            pickle.dump(self.wordToInt,fid)\n",
    "            pickle.dump(self.unigrams,fid)\n",
    "            pickle.dump(self.bigrams,fid)\n",
    "            if self.isTrigram:\n",
    "                pickle.dump(self.trigrams,fid)\n",
    "\n",
    "    def from_file(self,file):\n",
    "        import cPickle as pickle\n",
    "        with open(file,'r') as fid:\n",
    "            self.isTrigram, self.start, self.end, self.unk, self.scale = pickle.load(fid)\n",
    "            self.wordToInt = pickle.load(fid)\n",
    "            self.unigrams = pickle.load(fid)\n",
    "            self.bigrams = pickle.load(fid)\n",
    "            if self.isTrigram:\n",
    "                self.trigrams = pickle.load(fid)\n",
    "        self.dict_to_default_dict()\n",
    "\n",
    "if __name__=='__main__':\n",
    "#    lm = LM('/afs/cs.stanford.edu/u/awni/wsj/ctc-utils/lm_bg.arpa')\n",
    "#    print lm.wordToInt['ACCEPT']\n",
    "#    print lm.score_bg(\"HELLO AGAIN\")\n",
    "#    print lm.score_bg(\"HELLO ABDO\")\n",
    "\n",
    "#    lm = LM('/afs/cs.stanford.edu/u/awni/wsj/ctc-utils/lm_tg.arpa')\n",
    "    _arpa_path = \"./data\"\n",
    "    for p in os.listdir(_arpa_path):\n",
    "        file_path = os.path.join(_arpa_path,p)\n",
    "        if \"arpa\" in file_path:\n",
    "            print(\"processing\",file_path)\n",
    "            \n",
    "            lm = LM(file_path)\n",
    "            for wrd in range(len(lm.wordToInt)):\n",
    "                prob = lm.ug_prob(wrd)\n",
    "                print(prob)\n",
    "            \n",
    "# import os\n",
    "# # arpa\n",
    "# _arpa_path = \"./data\"\n",
    "# countdown = 0\n",
    "# for p in os.listdir(_arpa_path):\n",
    "#     file_path = os.path.join(_arpa_path,p)\n",
    "#     if \"arpa\" in file_path:\n",
    "#         print(\"processing\",file_path)\n",
    "#         with open (file_path, \"r\") as f:\n",
    "#             data = f.readlines()\n",
    "#         ngram2count = {}\n",
    "#         for n,header in enumerate(data[1:5]):\n",
    "#             nums = header.split(\"=\")[1].strip()\n",
    "#             ngram2count[n+1] = int(nums)\n",
    "#         print(ngram2count)\n",
    "#         for line in data[5:]:\n",
    "#             if \"\\\\\" in line and \"-grams\" in line:\n",
    "#                 print(line)\n",
    "#                 whichn = int(line[1])\n",
    "#                 countdown = ngram2count[whichn]\n",
    "#                 continue\n",
    "#             elif countdown > 0:\n",
    "#                 print(line.split())\n",
    "#                 s()\n",
    "#         print(data[:10])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8819b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing SBm.raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2931/2931 [00:00<00:00, 9714.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "_data_path = \"./data\"\n",
    "for p in os.listdir(_data_path):\n",
    "    file_path = os.path.join(_data_path,p)\n",
    "    if \"SBu.raw\" in file_path:\n",
    "        print(\"processing\",p)\n",
    "        \n",
    "        ngrams = {x:Counter() for x in range(1,5)}\n",
    "        ngrams[\"len\"] = Counter()\n",
    "        with open(file_path,\"r\") as f:\n",
    "            corpuss = f.readlines()\n",
    "        for l in tqdm(corpuss,total = len(corpuss)):\n",
    "            corpus_line = l.strip().split()\n",
    "            corpus_line2 = [corpus_line[i]+\"_\"+corpus_line[i+1] for i in range(len(corpus_line)-1)]\n",
    "            corpus_line3 = [corpus_line[i]+\"_\"+corpus_line[i+1]+\"_\"+corpus_line[i+2]  for i in range(len(corpus_line)-2)]\n",
    "            corpus_line4 = [corpus_line[i]+\"_\"+corpus_line[i+1]+\"_\"+corpus_line[i+2]+\"_\"+corpus_line[i+3] for i in range(len(corpus_line)-3)]\n",
    "            #print(corpus_line,corpus_line2)\n",
    "            ngrams[1].update(Counter(corpus_line))\n",
    "            ngrams[2].update(Counter(corpus_line2))\n",
    "            ngrams[3].update(Counter(corpus_line3))\n",
    "            ngrams[4].update(Counter(corpus_line4))\n",
    "            #print(corpus_line)\n",
    "            ngrams[\"len\"][len(corpus_line)] += 1\n",
    "            #s()\n",
    "        ngramsout = {x:[] for x in range(1,5)}\n",
    "        ngramsout[\"len\"] = []\n",
    "        for i in range(1,5):\n",
    "            ngramsout[i] = [k + \" \" + str(v) + \"\\n\" for k,v in ngrams[i].items()]\n",
    "            with open(os.path.join(_data_path,\"ngrams\",p+f\".{str(i)}gram\"),\"w\") as f:\n",
    "                f.writelines(ngramsout[i])\n",
    "        ngramsout[\"len\"] = [str(k) + \" \" + str(v) + \"\\n\" for k,v in ngrams[\"len\"].items()]\n",
    "        with open(os.path.join(_data_path,\"ngrams\",p+f\".len\"),\"w\") as f:\n",
    "            f.writelines(ngramsout[\"len\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec9235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
